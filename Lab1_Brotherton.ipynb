{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Matthew Brotherton","metadata":{}},{"cell_type":"markdown","source":"# CSC 4220 Lab 1 ","metadata":{}},{"cell_type":"markdown","source":"# 8/29/2020","metadata":{}},{"cell_type":"code","source":"#Importing libraries\n\nimport scipy\nimport numpy\nimport matplotlib\nimport pandas\nimport sklearn","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Then, we import the modules, functions, and objects that will be used.","metadata":{}},{"cell_type":"code","source":"#Load modules, functions, and objects\n\nfrom pandas import read_csv\nfrom pandas.plotting import scatter_matrix\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Next, we load the Iris dataset for this project.","metadata":{}},{"cell_type":"code","source":"# Load dataset\n\nurl = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\nnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\ndataset = read_csv(url, names=names)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we get a glimpse of the data's shape itself.","metadata":{}},{"cell_type":"code","source":"#Prints the dimensions of the dataset in the form instances, attributes\n\nprint(dataset.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is what displays from the previous command\n\n(150, 5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prints the first 20 rows of the data\n\nprint(dataset.head(20))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"  sepal-length  sepal-width  petal-length  petal-width        class\n0            5.1          3.5           1.4          0.2  Iris-setosa\n1            4.9          3.0           1.4          0.2  Iris-setosa\n2            4.7          3.2           1.3          0.2  Iris-setosa\n3            4.6          3.1           1.5          0.2  Iris-setosa\n4            5.0          3.6           1.4          0.2  Iris-setosa\n5            5.4          3.9           1.7          0.4  Iris-setosa\n6            4.6          3.4           1.4          0.3  Iris-setosa\n7            5.0          3.4           1.5          0.2  Iris-setosa\n8            4.4          2.9           1.4          0.2  Iris-setosa\n9            4.9          3.1           1.5          0.1  Iris-setosa\n10           5.4          3.7           1.5          0.2  Iris-setosa\n11           4.8          3.4           1.6          0.2  Iris-setosa\n12           4.8          3.0           1.4          0.1  Iris-setosa\n13           4.3          3.0           1.1          0.1  Iris-setosa\n14           5.8          4.0           1.2          0.2  Iris-setosa\n15           5.7          4.4           1.5          0.4  Iris-setosa\n16           5.4          3.9           1.3          0.4  Iris-setosa\n17           5.1          3.5           1.4          0.3  Iris-setosa\n18           5.7          3.8           1.7          0.3  Iris-setosa\n19           5.1          3.8           1.5          0.3  Iris-setosa","metadata":{}},{"cell_type":"raw","source":"Next, we can get a quick summary of the data with the following command.","metadata":{}},{"cell_type":"code","source":"#Gives the count, mean, std, min/max, and  various quartiles.\n\nprint(dataset.describe())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"       sepal-length  sepal-width  petal-length  petal-width\ncount    150.000000   150.000000    150.000000   150.000000\nmean       5.843333     3.054000      3.758667     1.198667\nstd        0.828066     0.433594      1.764420     0.763161\nmin        4.300000     2.000000      1.000000     0.100000\n25%        5.100000     2.800000      1.600000     0.300000\n50%        5.800000     3.000000      4.350000     1.300000\n75%        6.400000     3.300000      5.100000     1.800000\nmax        7.900000     4.400000      6.900000     2.500000","metadata":{}},{"cell_type":"code","source":"Now, we check how many groups exist within our data.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Shows the number of groups present\n\nprint(dataset.groupby('class').size())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"class\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50","metadata":{}},{"cell_type":"raw","source":"Next, we can move on to visualizing the data with various plots.","metadata":{}},{"cell_type":"code","source":"#Prints box and whisker plots\n\ndataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\npyplot.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"We follow up with a histogram.","metadata":{}},{"cell_type":"code","source":"#Prints histograms of each of the 4 attributes\n\ndataset.hist()\npyplot.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Then, we can create multivariate plots to analyze correlations.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prints a scatterplot matrix of attributes combined with other attributes (4x4=16 entries)\n\nscatter_matrix(dataset)\npyplot.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Before we can test algorithms, we need to create a test set.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating the test (train) and validation sets in a 80/20 split.\n\narray = dataset.values\nX = array[:,0:4]\ny = array[:,4]\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"To correctly test accuracy, we need to validate our data, and in this case, 10-fold for each unique algorithm and model we build.","metadata":{}},{"cell_type":"code","source":"#Running various algorithms and using 10 fold validation for each\n\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\n\n#Print results\n\nresults = []\nnames = []\nfor name, model in models:\n\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n\tresults.append(cv_results)\n\tnames.append(name)\n\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"The above code produces the following output.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"LR: 0.960897 (0.052113)\nLDA: 0.973974 (0.040110)\nKNN: 0.957191 (0.043263)\nCART: 0.957191 (0.043263)\nNB: 0.948858 (0.056322)\nSVM: 0.983974 (0.032083)","metadata":{}},{"cell_type":"code","source":"These numbers may be enough to select the best model, but we can also plot the differences.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare algorithms using a boxplot\n\npyplot.boxplot(results, labels=names)\npyplot.title('Algorithm Comparison')\npyplot.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Now that we have models, we can make predictions.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on validation dataset\n\nmodel = SVC(gamma='auto')\nmodel.fit(X_train, Y_train)\npredictions = model.predict(X_validation)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"We need to evaluate our models to see if our predictions are accurate.","metadata":{}},{"cell_type":"code","source":"# Evaluate predictions\n\nprint(accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"The following table is output.","metadata":{}},{"cell_type":"raw","source":"0.9666666666666667\n[[11  0  0]\n [ 0 12  1]\n [ 0  0  6]]\n                 precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        11\nIris-versicolor       1.00      0.92      0.96        13\n Iris-virginica       0.86      1.00      0.92         6\n\n       accuracy                           0.97        30\n      macro avg       0.95      0.97      0.96        30\n   weighted avg       0.97      0.97      0.97        30","metadata":{}},{"cell_type":"raw","source":"As we can see, the model strongly supports the predictions with high precision and recall.","metadata":{}}]}